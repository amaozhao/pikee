# PIKE-RAG åŸºç¡€ QA å·¥ä½œæµè¯¦è§£

## ğŸ“‹ æ•´ä½“æµç¨‹å›¾

```
ç”¨æˆ·æ‰§è¡Œå‘½ä»¤
    â†“
python examples/qa.py examples/hotpotqa/configs/qa_chunk.yml
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹åŒ–ï¼ˆQaWorkflow.__init__ï¼‰                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. åŠ è½½ YAML é…ç½®                                            â”‚
â”‚ 2. åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ                                            â”‚
â”‚ 3. åŠ è½½æµ‹è¯•æ•°æ®é›†                                            â”‚
â”‚ 4. åˆå§‹åŒ– Agent ç»„ä»¶ï¼š                                       â”‚
â”‚    â”œâ”€â”€ QA æç¤ºåè®®ï¼ˆProtocolï¼‰                               â”‚
â”‚    â”œâ”€â”€ çŸ¥è¯†æ£€ç´¢å™¨ï¼ˆRetrieverï¼‰                               â”‚
â”‚    â””â”€â”€ LLM å®¢æˆ·ç«¯ï¼ˆClientï¼‰                                 â”‚
â”‚ 5. åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆEvaluatorï¼‰                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬äºŒé˜¶æ®µï¼šæ‰§è¡Œï¼ˆQaWorkflow.runï¼‰                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜å¾ªç¯æ‰§è¡Œï¼š                                      â”‚
â”‚    â†“                                                        â”‚
â”‚  ã€QaWorkflow.answer æ–¹æ³•ã€‘                                 â”‚
â”‚    â”œâ”€â”€ Step 1: æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆRetrieverï¼‰                    â”‚
â”‚    â”œâ”€â”€ Step 2: æ„å»ºæç¤ºï¼ˆProtocol.process_inputï¼‰          â”‚
â”‚    â”œâ”€â”€ Step 3: LLM ç”Ÿæˆå›ç­”ï¼ˆClient.generateï¼‰             â”‚
â”‚    â”œâ”€â”€ Step 4: è§£æè¾“å‡ºï¼ˆProtocol.parse_outputï¼‰           â”‚
â”‚    â””â”€â”€ Step 5: è¯„ä¼°ç­”æ¡ˆï¼ˆEvaluatorï¼‰                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬ä¸‰é˜¶æ®µï¼šè¾“å‡ºç»“æœ                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. ä¿å­˜æ‰€æœ‰ QA ç»“æœåˆ° JSONL æ–‡ä»¶                            â”‚
â”‚ 2. ç”Ÿæˆè¯„ä¼°æŒ‡æ ‡æŠ¥å‘Šï¼ˆEM, F1, Precision, Recallï¼‰            â”‚
â”‚ 3. ä¿å­˜æ—¥å¿—æ–‡ä»¶                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ è¯¦ç»†ä»£ç è°ƒç”¨æµç¨‹

### **é˜¶æ®µ 1ï¼šç¨‹åºå¯åŠ¨å’Œé…ç½®åŠ è½½**

#### Step 1.1: å…¥å£ç‚¹ - `examples/qa.py`

```python
if __name__ == "__main__":
    # 1. è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œè·å–é…ç½®æ–‡ä»¶è·¯å¾„
    parser = argparse.ArgumentParser()
    parser.add_argument("config", type=str, help="yamlé…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()
    
    # 2. åŠ è½½å¹¶å¤„ç† YAML é…ç½®
    yaml_config: dict = load_yaml_config(args.config, args)
    # è¿™ä¸€æ­¥ä¼šï¼š
    #   - è¯»å– YAML æ–‡ä»¶
    #   - åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆå¦‚ logs/hotpotqa/naive_rag/ï¼‰
    #   - è®¾ç½®å„ç§è·¯å¾„
    
    # 3. åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆAzure API keysç­‰ï¼‰
    load_dot_env(env_path=yaml_config.get("dotenv_path", None))
    
    # 4. åŠ¨æ€å¯¼å…¥å·¥ä½œæµç±»
    # ä» yaml_config["workflow"]["module_path"] å¯¼å…¥
    # å¯¹äºåŸºç¡€ QA: pikerag.workflows.qa.QaWorkflow
    workflow_module = importlib.import_module(yaml_config["workflow"]["module_path"])
    workflow_class = getattr(workflow_module, yaml_config["workflow"]["class_name"])
    
    # 5. å®ä¾‹åŒ–å·¥ä½œæµï¼ˆè¿™ä¼šè§¦å‘æ‰€æœ‰åˆå§‹åŒ–ï¼‰
    workflow = workflow_class(yaml_config)
    
    # 6. è¿è¡Œå·¥ä½œæµ
    workflow.run()
```

**å…³é”®ç‚¹ï¼š** ä½¿ç”¨ Python çš„åŠ¨æ€å¯¼å…¥æœºåˆ¶ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶çµæ´»åˆ‡æ¢ä¸åŒçš„å·¥ä½œæµã€‚

---

### **é˜¶æ®µ 2ï¼šå·¥ä½œæµåˆå§‹åŒ– - `QaWorkflow.__init__`**

åˆå§‹åŒ–è¿‡ç¨‹åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

```python
def __init__(self, yaml_config: dict) -> None:
    self._yaml_config: dict = yaml_config
    
    # Step 2.1: åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    self._init_logger()
    
    # Step 2.2: åŠ è½½æµ‹è¯•æ•°æ®é›†
    self._load_testing_suite()
    
    # Step 2.3: åˆå§‹åŒ– Agentï¼ˆæ ¸å¿ƒç»„ä»¶ï¼‰
    self._init_agent()
    
    # Step 2.4: åˆå§‹åŒ–è¯„ä¼°å™¨
    self._init_evaluator()
    
    # Step 2.5: åˆå§‹åŒ– QA æŒ‡æ ‡è¡¨
    self._init_qas_metrics_table()
```

---

#### **Step 2.2: åŠ è½½æµ‹è¯•æ•°æ®é›†** (`_load_testing_suite`)

```python
def _load_testing_suite(self) -> None:
    # 1. åŠ¨æ€å¯¼å…¥æ•°æ®åŠ è½½å‡½æ•°
    #    å¯¹äº HotpotQA: pikerag.utils.data_protocol_utils.load_testing_suite
    test_loading_module = importlib.import_module(
        self._yaml_config["test_loading"]["module"]
    )
    test_loading_func = getattr(
        test_loading_module, 
        self._yaml_config["test_loading"]["name"]
    )
    
    # 2. è°ƒç”¨åŠ è½½å‡½æ•°ï¼Œä¼ å…¥å‚æ•°ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ï¼‰
    #    args: {'filepath': 'data/hotpotqa/dev_500.jsonl'}
    self._testing_suite: List[BaseQaData] = test_loading_func(
        **self._yaml_config["test_loading"]["args"]
    )
    
    # 3. éªŒè¯æ•°æ®ç±»å‹
    assert isinstance(self._testing_suite[0], BaseQaData)
    
    # 4. è®°å½•æµ‹è¯•æ•°æ®æ•°é‡
    self._num_test: int = len(self._testing_suite)
```

**æ•°æ®åŠ è½½å‡½æ•°å®é™…æ‰§è¡Œï¼š** `pikerag/utils/data_protocol_utils.py`

```python
def load_testing_suite(filepath: str) -> List[GenerationQaData]:
    testing_suite = []
    with jsonlines.open(filepath, "r") as reader:
        for qa in reader:
            # æ¯ä¸€è¡Œ JSONL æ•°æ®æ ¼å¼ï¼š
            # {
            #   "id": "5a7a06935542990198eaf050",
            #   "question": "Which magazine was started first Arthur's Magazine or First for Women?",
            #   "answer_labels": ["Arthur's Magazine"],
            #   "question_type": "comparison",
            #   "metadata": {...}
            # }
            
            testing_suite.append(
                GenerationQaData(
                    question=qa["question"],
                    answer_labels=[str(label) for label in qa["answer_labels"]],
                    metadata=qa["metadata"],
                )
            )
    return testing_suite
```

**æ•°æ®ç»“æ„ï¼š** `GenerationQaData`

```python
@dataclass
class GenerationQaData(BaseQaData):
    # æ ‡å‡†ç­”æ¡ˆåˆ—è¡¨ï¼ˆç”¨äºè¯„ä¼°ï¼‰
    answer_labels: List[str] = field(default_factory=lambda: [])
    
    # æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ
    answer: str = field(default_factory=lambda: "")
    
    def __post_init__(self) -> None:
        # å¯¹ç­”æ¡ˆè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ˆå°å†™ã€å»æ ‡ç‚¹ç­‰ï¼‰
        self.answer_labels = [normalize_answer(answer) for answer in self.answer_labels]
```

---

#### **Step 2.3: åˆå§‹åŒ– Agent** (`_init_agent`)

è¿™æ˜¯æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼ŒåŒ…å«ä¸‰ä¸ªå­ç»„ä»¶ï¼š

```python
def _init_agent(self) -> None:
    """åˆå§‹åŒ– Agent çš„ä¸‰å¤§æ ¸å¿ƒç»„ä»¶"""
    
    # 2.3.1: åˆå§‹åŒ– QA é€šä¿¡åè®®ï¼ˆæç¤ºæ¨¡æ¿ï¼‰
    self._init_protocol()
    
    # 2.3.2: åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢å™¨
    self._init_retriever()
    
    # 2.3.3: åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    self._init_llm_client()
```

##### **2.3.1: åˆå§‹åŒ– QA åè®®** (`_init_protocol`)

```python
def _init_protocol(self) -> None:
    # ä»é…ç½®åŠ è½½åè®®
    # å¯¹äºåŸºç¡€ QA: pikerag.prompts.qa.generation_qa_with_reference_protocol
    self._qa_protocol = load_protocol(
        module_path=self._yaml_config["qa_protocol"]["module_path"],
        protocol_name=self._yaml_config["qa_protocol"]["attr_name"],
        partial_values=self._yaml_config["qa_protocol"].get("template_partial", {}),
    )
```

**åè®®å¯¹è±¡åŒ…å«ï¼š**

```python
generation_qa_with_reference_protocol = CommunicationProtocol(
    template=generation_qa_with_reference_template,  # æç¤ºæ¨¡æ¿
    parser=GenerationQaParser(),                      # è¾“å…¥/è¾“å‡ºè§£æå™¨
)
```

**æç¤ºæ¨¡æ¿å†…å®¹ï¼š**

```python
generation_qa_with_reference_template = MessageTemplate(
    template=[
        ("system", "{system_prompt}"),  # ç³»ç»Ÿæç¤º
        ("user", """
# Task
Your task is to answer a question referring to a given context, if any.
For answering the Question at the end, you need to first read the context provided, 
then give your final answer.

# Output format
Your output should strictly follow the format below. Make sure your output parsable by json in Python.
{{
    "answer": <A string. Your Answer.>,
    "rationale": <A string. Rationale behind your choice>
}}

# Context, if any
{context_if_any}

# Question
{content}{yes_or_no_limit}

Let's think step by step.
""".strip()),
    ],
    input_variables=["content", "context_if_any", "yes_or_no_limit"],
    partial_variables={"system_prompt": DEFAULT_SYSTEM_PROMPT},
)
```

---

##### **2.3.2: åˆå§‹åŒ–æ£€ç´¢å™¨** (`_init_retriever`)

```python
def _init_retriever(self) -> None:
    retriever_config: dict = self._yaml_config["retriever"]
    
    # 1. åŠ¨æ€åŠ è½½æ£€ç´¢å™¨ç±»
    # å¯¹äºåŸºç¡€ QA: pikerag.knowledge_retrievers.QaChunkRetriever
    retriever_class = load_class(
        module_path=retriever_config["module_path"],
        class_name=retriever_config["class_name"],
        base_class=BaseQaRetriever
    )
    
    # 2. å®ä¾‹åŒ–æ£€ç´¢å™¨
    self._retriever = retriever_class(
        retriever_config=retriever_config["args"],
        log_dir=self._yaml_config["log_dir"],
        main_logger=self._logger,
    )
```

**æ£€ç´¢å™¨åˆå§‹åŒ–è¿‡ç¨‹ï¼š** `QaChunkRetriever.__init__`

```python
def __init__(self, retriever_config: dict, log_dir: str, main_logger: Logger) -> None:
    super().__init__(retriever_config, log_dir, main_logger)
    
    # Step A: åˆå§‹åŒ–æŸ¥è¯¢è§£æå™¨
    # é»˜è®¤ï¼šquestion_as_queryï¼ˆç›´æ¥ç”¨é—®é¢˜ä½œä¸ºæŸ¥è¯¢ï¼‰
    self._init_query_parser()
    
    # Step B: åŠ è½½å‘é‡æ•°æ®åº“
    # è¿™ä¼šåŠ è½½é¢„å…ˆæ„å»ºå¥½çš„ Chroma å‘é‡å­˜å‚¨
    self._load_vector_store()
    
    # Step C: åˆå§‹åŒ– Chroma æ··å…¥ï¼ˆæä¾›å‘é‡æ£€ç´¢æ–¹æ³•ï¼‰
    self._init_chroma_mixin()
```

**å‘é‡æ•°æ®åº“åŠ è½½ï¼š**

```python
def _load_vector_store(self) -> None:
    vector_store_config = self._retriever_config["vector_store"]
    
    # è°ƒç”¨è¾…åŠ©å‡½æ•°åŠ è½½å‘é‡å­˜å‚¨
    self.vector_store: Chroma = load_vector_store_from_configs(
        vector_store_config=vector_store_config,
        embedding_config=vector_store_config.get("embedding_setting", {}),
        collection_name=vector_store_config.get("collection_name", self.name),
        persist_directory=vector_store_config.get("persist_directory"),
    )
```

```python
def load_vector_store_from_configs(...) -> Chroma:
    # 1. åŠ è½½ Embedding å‡½æ•°ï¼ˆå¦‚ Azure OpenAI Embeddingï¼‰
    embedding = load_embedding_func(
        module_path=embedding_config.get("module_path"),
        class_name=embedding_config.get("class_name"),
        **embedding_config.get("args", {}),
    )
    
    # 2. åŠ è½½æ–‡æ¡£æ•°æ®
    # è°ƒç”¨ï¼špikerag.utils.data_protocol_utils.load_ids_and_chunks
    loading_configs = vector_store_config["id_document_loading"]
    ids, documents = load_callable(...)(
        **loading_configs.get("args", {})
    )
    # è¿”å›ï¼š
    #   ids: ["chunk_0001", "chunk_0002", ...]
    #   documents: [Document(page_content=..., metadata=...), ...]
    
    # 3. æ„å»ºæˆ–åŠ è½½å‘é‡å­˜å‚¨
    vector_store = load_vector_store(
        collection_name, persist_directory, 
        embedding, documents, ids, exist_ok
    )
    return vector_store
```

---

##### **2.3.3: åˆå§‹åŒ– LLM å®¢æˆ·ç«¯** (`_init_llm_client`)

```python
def _init_llm_client(self) -> None:
    # 1. åˆ›å»ºå®¢æˆ·ç«¯æ—¥å¿—å™¨
    self._client_logger = Logger(
        name="client", 
        dump_mode="a",  # è¿½åŠ æ¨¡å¼
        dump_folder=self._yaml_config["log_dir"]
    )
    
    llm_client_config = self._yaml_config["llm_client"]
    
    # 2. åŠ¨æ€å¯¼å…¥ LLM å®¢æˆ·ç«¯ç±»
    # å¯¹äº Azure OpenAI: pikerag.llm_client.AzureOpenAIClient
    client_module = importlib.import_module(llm_client_config["module_path"])
    client_class = getattr(client_module, llm_client_config["class_name"])
    
    # 3. æå– LLM é…ç½®
    self.llm_config = llm_client_config["llm_config"]
    # ä¾‹å¦‚: {"model": "gpt-4", "temperature": 0}
    
    # 4. å®ä¾‹åŒ–å®¢æˆ·ç«¯
    self._client = client_class(
        location=None,  # ç¼“å­˜ä½ç½®ç¨åè®¾ç½®
        auto_dump=llm_client_config["cache_config"]["auto_dump"],
        logger=self._client_logger,
        llm_config=self.llm_config,
        **llm_client_config.get("args", {}),
    )
```

**LLM å®¢æˆ·ç«¯ç‰¹æ€§ï¼š**
- **ç¼“å­˜æœºåˆ¶ï¼š** ç›¸åŒçš„è¾“å…¥ä¸ä¼šé‡å¤è°ƒç”¨ APIï¼ŒèŠ‚çœæˆæœ¬
- **ç»Ÿä¸€æ¥å£ï¼š** æ”¯æŒå¤šç§ LLM æä¾›å•†ï¼ˆAzure OpenAIã€HuggingFaceç­‰ï¼‰
- **æ—¥å¿—è®°å½•ï¼š** æ‰€æœ‰ LLM è¯·æ±‚å’Œå“åº”éƒ½ä¼šè¢«è®°å½•

---

### **é˜¶æ®µ 3ï¼šæ‰§è¡Œé—®ç­”æµç¨‹ - `QaWorkflow.run`**

åˆå§‹åŒ–å®Œæˆåï¼Œå¼€å§‹æ‰§è¡Œæµ‹è¯•ï¼š

```python
def _single_thread_run(self) -> None:
    # 1. æ‰“å¼€è¾“å‡ºæ–‡ä»¶ï¼ˆç”¨äºä¿å­˜æ‰€æœ‰ QA ç»“æœï¼‰
    fout = jsonlines.open(self._yaml_config["test_jsonl_path"], "w")
    
    # 2. å¯¹æ¯ä¸€è½®æµ‹è¯•æ‰§è¡Œï¼ˆé€šå¸¸æ˜¯1è½®ï¼‰
    for round_idx in range(self._yaml_config["test_rounds"]):
        round_id: str = f"Round{round_idx}"
        
        # 2.1: æ›´æ–° LLM ç¼“å­˜ä½ç½®
        self._update_llm_cache(round_idx)
        
        # 2.2: é€šçŸ¥è¯„ä¼°å™¨ï¼šæ–°ä¸€è½®å¼€å§‹
        self._evaluator.on_round_test_start(round_id)
        
        # 2.3: éå†æ‰€æœ‰æµ‹è¯•é—®é¢˜
        question_idx: int = 0
        pbar = tqdm(self._testing_suite, desc=f"...")
        for qa in pbar:
            # ã€æ ¸å¿ƒã€‘è°ƒç”¨ answer æ–¹æ³•å›ç­”é—®é¢˜
            output_dict: dict = self.answer(qa, question_idx)
            
            # 2.4: æ›´æ–° QA æ•°æ®å¯¹è±¡
            answer = output_dict.pop("answer")
            qa.update_answer(answer)  # è®¾ç½®ç”Ÿæˆçš„ç­”æ¡ˆ
            qa.answer_metadata.update(output_dict)  # ä¿å­˜å…¶ä»–å…ƒæ•°æ®
            
            # 2.5: è¯„ä¼°ç­”æ¡ˆè´¨é‡
            self._evaluator.update_round_metrics(qa)
            
            # 2.6: ä¿å­˜ç»“æœ
            fout.write(qa.as_dict())
            self._update_qas_metrics_table(qa)
            
            question_idx += 1
            
            # 2.7: æ›´æ–°è¿›åº¦æ¡ï¼ˆæ˜¾ç¤ºå®æ—¶æŒ‡æ ‡ï¼‰
            self._update_pbar_desc(pbar, round_idx=round_idx, count=question_idx)
        
        # 2.8: ä¸€è½®ç»“æŸ
        self._evaluator.on_round_test_end(round_id)
    
    # 3. æ‰€æœ‰æµ‹è¯•ç»“æŸ
    self._evaluator.on_test_end()
    fout.close()
```

---

### **é˜¶æ®µ 4ï¼šæ ¸å¿ƒç­”é¢˜é€»è¾‘ - `QaWorkflow.answer`** â­â­â­

è¿™æ˜¯æœ€æ ¸å¿ƒçš„æ–¹æ³•ï¼Œå¤„ç†å•ä¸ªé—®é¢˜çš„å®Œæ•´æµç¨‹ï¼š

```python
def answer(self, qa: BaseQaData, question_idx: int) -> dict:
    """ç»™å®šä¸€ä¸ªé—®é¢˜ï¼Œæ‰§è¡Œå†³ç­–è¿‡ç¨‹ç”Ÿæˆç­”æ¡ˆ
    
    è¿™é‡Œå®ç°çš„æ˜¯ï¼šå•æ¬¡ LLM è°ƒç”¨ + å¯é€‰çš„æ£€ç´¢å¢å¼º
    """
    
    # ========== Step 1: æ£€ç´¢ç›¸å…³æ–‡æ¡£ ==========
    reference_chunks: List[str] = self._retriever.retrieve_contents(
        qa, 
        retrieve_id=f"Q{question_idx:03}"
    )
    
    # ========== Step 2: æ„å»ºæç¤ºæ¶ˆæ¯ ==========
    messages = self._qa_protocol.process_input(
        content=qa.question,
        references=reference_chunks,
        **qa.as_dict()
    )
    
    # ========== Step 3: LLM ç”Ÿæˆå†…å®¹ ==========
    response = self._client.generate_content_with_messages(
        messages, 
        **self.llm_config
    )
    
    # ========== Step 4: è§£æ LLM è¾“å‡º ==========
    output_dict: dict = self._qa_protocol.parse_output(
        response, 
        **qa.as_dict()
    )
    
    # ========== Step 5: æ·»åŠ å…ƒæ•°æ® ==========
    if "response" not in output_dict:
        output_dict["response"] = response
    
    if "reference_chunks" not in output_dict:
        output_dict["reference_chunks"] = reference_chunks
    
    return output_dict
```

---

## ğŸ“– è¯¦ç»†æ­¥éª¤æ‹†è§£

### **Step 1: æ£€ç´¢ç›¸å…³æ–‡æ¡£**

```python
reference_chunks: List[str] = self._retriever.retrieve_contents(
    qa, retrieve_id=f"Q{question_idx:03}"
)
```

**æ£€ç´¢å™¨æ‰§è¡Œæµç¨‹ï¼š** `QaChunkRetriever.retrieve_contents`

```python
def retrieve_contents(self, qa: BaseQaData, retrieve_id: str="") -> List[str]:
    # A. æŸ¥è¯¢è§£æï¼šå°† QA å¯¹è±¡è½¬æ¢ä¸ºæŸ¥è¯¢å­—ç¬¦ä¸²
    queries: List[str] = self._query_parser(qa)
    # å¯¹äº question_as_query: è¿”å› [qa.question]
    
    # B. è®¡ç®—æ¯ä¸ªæŸ¥è¯¢çš„ top-k
    retrieve_k = math.ceil(self.retrieve_k / len(queries))
    # å¦‚æœé…ç½® retrieve_k=16ï¼Œåªæœ‰1ä¸ªæŸ¥è¯¢ï¼Œé‚£ä¹ˆ retrieve_k=16
    
    # C. å¯¹æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œå‘é‡æ£€ç´¢
    all_chunks: List[str] = []
    for query in queries:
        chunks = self.retrieve_contents_by_query(
            query, retrieve_id, retrieve_k=retrieve_k
        )
        all_chunks.extend(chunks)
    
    # D. è®°å½•æ—¥å¿—
    self.logger.debug(f"{retrieve_id}: {len(all_chunks)} strings returned.")
    
    return all_chunks
```

**å‘é‡æ£€ç´¢ç»†èŠ‚ï¼š**

```python
def retrieve_contents_by_query(self, query: str, ...) -> List[str]:
    # 1. æ‰§è¡Œå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
    chunk_infos = self._get_doc_and_score_with_query(query, ...)
    # è¿”å›: [(Documentå¯¹è±¡, ç›¸ä¼¼åº¦åˆ†æ•°), ...]
    
    # 2. æå–æ–‡æ¡£å†…å®¹
    return self._get_relevant_strings(chunk_infos, retrieve_id)
    # è¿”å›: ["chunkå†…å®¹1", "chunkå†…å®¹2", ...]
```

**æ£€ç´¢ç»“æœç¤ºä¾‹ï¼š**
```python
reference_chunks = [
    "Arthur's Magazine was an American literary periodical published from 1844 to 1846...",
    "First for Women is a woman's magazine published by Bauer Media Group...",
    # ... æ›´å¤šç›¸å…³æ–‡æ¡£ç‰‡æ®µ
]
```

---

### **Step 2: æ„å»ºæç¤ºæ¶ˆæ¯**

```python
messages = self._qa_protocol.process_input(
    content=qa.question,
    references=reference_chunks,
    **qa.as_dict()
)
```

**åè®®å¤„ç†è¾“å…¥ï¼š** `GenerationQaParser.encode`

```python
def encode(self, content: str, references: List[str]=[], 
           context_len_limit: int=80000, **kwargs) -> Tuple[str, dict]:
    # A. æ„å»º yes/no é™åˆ¶æŒ‡ä»¤
    answer_labels = kwargs.get("answer_labels", [])
    if len(answer_labels) == 1 and answer_labels[0] in ["yes", "no"]:
        yes_or_no_limit = """ Your answer shall be "Yes" or "No"."""
    else:
        yes_or_no_limit = ""
    
    # B. æ„å»ºå‚è€ƒä¸Šä¸‹æ–‡
    context_if_any = ""
    for context in list(set(references)):  # å»é‡
        context_if_any += f"\n{context}\n"
        if len(context_if_any) >= context_len_limit:  # é˜²æ­¢è¶…é•¿
            break
    
    # C. è¿”å›é—®é¢˜å’Œæ¨¡æ¿å˜é‡
    return content, {
        "yes_or_no_limit": yes_or_no_limit,
        "context_if_any": context_if_any,
    }
```

**ç”Ÿæˆçš„æ¶ˆæ¯ç»“æ„ï¼š**
```python
messages = [
    {
        "role": "system",
        "content": "You are a helpful AI assistant on question answering."
    },
    {
        "role": "user",
        "content": """
# Task
Your task is to answer a question referring to a given context, if any.
...

# Context, if any

Arthur's Magazine was an American literary periodical published from 1844 to 1846...

First for Women is a woman's magazine published by Bauer Media Group...

# Question
Which magazine was started first Arthur's Magazine or First for Women?

Let's think step by step.
"""
    }
]
```

---

### **Step 3: LLM ç”Ÿæˆå†…å®¹**

```python
response = self._client.generate_content_with_messages(
    messages, **self.llm_config
)
```

**LLM å®¢æˆ·ç«¯æ‰§è¡Œï¼š**
1. æ£€æŸ¥ç¼“å­˜ï¼šå¦‚æœç›¸åŒçš„ messages ä¹‹å‰è°ƒç”¨è¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
2. å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè°ƒç”¨ Azure OpenAI API
3. è®°å½•è¯·æ±‚å’Œå“åº”åˆ°æ—¥å¿—
4. ä¿å­˜åˆ°ç¼“å­˜
5. è¿”å›ç”Ÿæˆçš„æ–‡æœ¬

**LLM å“åº”ç¤ºä¾‹ï¼š**
```json
{
    "answer": "Arthur's Magazine",
    "rationale": "Arthur's Magazine was published from 1844 to 1846, while First for Women was founded later. Therefore, Arthur's Magazine was started first."
}
```

---

### **Step 4: è§£æ LLM è¾“å‡º**

```python
output_dict: dict = self._qa_protocol.parse_output(
    response, **qa.as_dict()
)
```

**è§£æå™¨æ‰§è¡Œï¼š** `GenerationQaParser.decode`

```python
def decode(self, content: str, **kwargs) -> Dict[str, str]:
    try:
        # å°è¯•è§£æ JSON
        output = parse_json(content)
        # parse_json ä¼šå¤„ç†å„ç§æ ¼å¼é—®é¢˜ï¼Œå¦‚ï¼š
        #   - Markdown ä»£ç å—åŒ…è£¹çš„ JSON
        #   - æ³¨é‡Š
        #   - ä¸æ ‡å‡†çš„å¼•å·ç­‰
    except Exception as e:
        print(f"[GenerationQaParser] Exception: {e}")
        return {
            "answer": "parsing error",
            "rationale": "parsing error",
        }
    
    # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å­—ç¬¦ä¸²
    for key, value in output.items():
        output[key] = str(value)
    
    return output
```

**è§£æç»“æœï¼š**
```python
output_dict = {
    "answer": "Arthur's Magazine",
    "rationale": "Arthur's Magazine was published from 1844..."
}
```

---

### **Step 5: æ·»åŠ å…ƒæ•°æ®å¹¶è¿”å›**

```python
# ä¿å­˜åŸå§‹ LLM å“åº”
if "response" not in output_dict:
    output_dict["response"] = response

# ä¿å­˜æ£€ç´¢åˆ°çš„æ–‡æ¡£
if "reference_chunks" not in output_dict:
    output_dict["reference_chunks"] = reference_chunks

return output_dict
```

**æœ€ç»ˆè¿”å›çš„å­—å…¸ï¼š**
```python
{
    "answer": "Arthur's Magazine",
    "rationale": "...",
    "response": "{\"answer\": \"Arthur's Magazine\", \"rationale\": \"...\"}",
    "reference_chunks": ["chunk1", "chunk2", ...]
}
```

---

### **é˜¶æ®µ 5ï¼šè¯„ä¼°ç­”æ¡ˆ**

å›åˆ° `run` æ–¹æ³•ï¼Œanswer è¿”å›åï¼š

```python
# 1. æå–ç­”æ¡ˆå¹¶æ›´æ–° QA å¯¹è±¡
answer = output_dict.pop("answer")
qa.update_answer(answer)  # è®¾ç½® qa.answer = "Arthur's Magazine"

# 2. ä¿å­˜å…¶ä»–å…ƒæ•°æ®
qa.answer_metadata.update(output_dict)

# 3. è¯„ä¼°ç­”æ¡ˆ
self._evaluator.update_round_metrics(qa)
# è¿™ä¼šè®¡ç®—ï¼š
#   - ExactMatch: qa.answer == qa.answer_labels[0] ? 1 : 0
#   - F1: è®¡ç®— token çº§åˆ«çš„ F1 åˆ†æ•°
#   - Precision, Recall ç­‰
```

**è¯„ä¼°ç»“æœä¿å­˜åœ¨ `qa.answer_metric_scores` ä¸­ï¼š**
```python
qa.answer_metric_scores = {
    "ExactMatch": 1.0,
    "F1": 1.0,
    "Precision": 1.0,
    "Recall": 1.0,
}
```

---

## ğŸ“Š å®Œæ•´æ•°æ®æµç¤ºæ„å›¾

```
è¾“å…¥: "Which magazine was started first Arthur's Magazine or First for Women?"
    â†“
ã€æ£€ç´¢å™¨ã€‘â†’ å‘é‡æ•°æ®åº“æŸ¥è¯¢
    â†“
æ£€ç´¢ç»“æœ: [
    "Arthur's Magazine was published from 1844...",
    "First for Women is a magazine...",
    ...
]
    â†“
ã€åè®®å¤„ç†ã€‘â†’ æ„å»ºæç¤º
    â†“
æç¤ºæ¶ˆæ¯: {
    system: "You are a helpful AI assistant...",
    user: "# Context\n...\n# Question\n..."
}
    â†“
ã€LLM å®¢æˆ·ç«¯ã€‘â†’ è°ƒç”¨ GPT-4
    â†“
LLM å“åº”: {"answer": "Arthur's Magazine", "rationale": "..."}
    â†“
ã€åè®®è§£æã€‘â†’ JSON è§£æ
    â†“
è¾“å‡ºå­—å…¸: {"answer": "Arthur's Magazine", "rationale": "...", ...}
    â†“
ã€è¯„ä¼°å™¨ã€‘â†’ å¯¹æ¯”æ ‡å‡†ç­”æ¡ˆ
    â†“
æŒ‡æ ‡: {ExactMatch: 1.0, F1: 1.0, ...}
    â†“
ä¿å­˜åˆ° JSONL æ–‡ä»¶
```

---

## ğŸ¯ å…³é”®è®¾è®¡æ¨¡å¼å’Œä¼˜åŠ¿

### 1. **åŠ¨æ€å¯¼å…¥æœºåˆ¶**
```python
# æ‰€æœ‰ç»„ä»¶éƒ½é€šè¿‡é…ç½®æ–‡ä»¶åŠ¨æ€åŠ è½½
workflow_class = getattr(importlib.import_module(path), name)
```
**ä¼˜åŠ¿ï¼š** æ— éœ€ä¿®æ”¹ä»£ç ï¼Œåªéœ€ä¿®æ”¹ YAML é…ç½®å³å¯åˆ‡æ¢ä¸åŒçš„æ£€ç´¢å™¨ã€LLMã€å·¥ä½œæµç­‰ã€‚

### 2. **åè®®æ¨¡å¼ï¼ˆProtocol Patternï¼‰**
```python
# æç¤ºæ¨¡æ¿ + è¾“å…¥è¾“å‡ºè§£æå™¨ = é€šä¿¡åè®®
protocol = CommunicationProtocol(template, parser)
```
**ä¼˜åŠ¿ï¼š** æç¤ºå·¥ç¨‹æ¨¡å—åŒ–ï¼Œæ˜“äºæµ‹è¯•å’Œå¤ç”¨ã€‚

### 3. **ç¼“å­˜æœºåˆ¶**
```python
# LLM å®¢æˆ·ç«¯è‡ªåŠ¨ç¼“å­˜ç›¸åŒè¾“å…¥çš„å“åº”
self._client.generate_content_with_messages(messages, ...)
```
**ä¼˜åŠ¿ï¼š** èŠ‚çœæˆæœ¬ï¼ŒåŠ é€Ÿè°ƒè¯•ï¼ˆé‡å¤è¿è¡Œä¸ä¼šé‡å¤è°ƒç”¨ APIï¼‰ã€‚

### 4. **æ—¥å¿—ç³»ç»Ÿ**
```python
# å¤šå±‚æ¬¡çš„æ—¥å¿—è®°å½•
- ä¸»æ—¥å¿—å™¨ï¼šè®°å½•å·¥ä½œæµäº‹ä»¶
- å®¢æˆ·ç«¯æ—¥å¿—å™¨ï¼šè®°å½•æ‰€æœ‰ LLM è¯·æ±‚
- æ£€ç´¢å™¨æ—¥å¿—å™¨ï¼šè®°å½•æ£€ç´¢è¯¦æƒ…
```
**ä¼˜åŠ¿ï¼š** å®Œæ•´çš„å¯è¿½æº¯æ€§ï¼Œä¾¿äºè°ƒè¯•å’Œåˆ†æã€‚

---

## ğŸ“ æ€»ç»“

åŸºç¡€ QA å·¥ä½œæµçš„æ ¸å¿ƒå°±æ˜¯ï¼š

```
é—®é¢˜ â†’ æ£€ç´¢ â†’ æç¤ºæ„å»º â†’ LLMç”Ÿæˆ â†’ è§£æ â†’ è¯„ä¼°
```

è™½ç„¶çœ‹èµ·æ¥ç®€å•ï¼Œä½† PIKE-RAG çš„ä¼˜åŠ¿åœ¨äºï¼š
1. **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹æ›¿æ¢
2. **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡ YAML çµæ´»é…ç½®
3. **æ™ºèƒ½æ£€ç´¢**ï¼šæ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥
4. **å®Œå–„çš„æ—¥å¿—**ï¼šæ‰€æœ‰è¿‡ç¨‹å¯è¿½æº¯
5. **ç¼“å­˜ä¼˜åŒ–**ï¼šé¿å…é‡å¤è°ƒç”¨ï¼ŒèŠ‚çœæˆæœ¬

---

## ğŸš€ é…ç½®æ–‡ä»¶ç¤ºä¾‹

å®Œæ•´çš„ YAML é…ç½®æ–‡ä»¶ç»“æ„ï¼š

```yaml
# å®éªŒè®¾ç½®
experiment_name: naive_rag
log_root_dir: logs/hotpotqa
test_rounds: 1

# å·¥ä½œæµé…ç½®
workflow:
  module_path: pikerag.workflows.qa
  class_name: QaWorkflow

# æµ‹è¯•æ•°æ®
test_loading:
  module: pikerag.utils.data_protocol_utils
  name: load_testing_suite
  args:
    filepath: data/hotpotqa/dev_500.jsonl

# LLM é…ç½®
llm_client:
  module_path: pikerag.llm_client
  class_name: AzureOpenAIClient
  llm_config:
    model: gpt-4
    temperature: 0
  cache_config:
    auto_dump: True

# æ£€ç´¢å™¨é…ç½®
retriever:
  module_path: pikerag.knowledge_retrievers
  class_name: QaChunkRetriever
  args:
    retrieve_k: 16
    retrieve_score_threshold: 0.2
    vector_store:
      collection_name: dev_500_chunks_ada
      persist_directory: data/vector_stores/hotpotqa

# æç¤ºæ¨¡æ¿é…ç½®
qa_protocol:
  module_path: pikerag.prompts.qa
  attr_name: generation_qa_with_reference_protocol

# è¯„ä¼°æŒ‡æ ‡
evaluator:
  metrics:
    - ExactMatch
    - F1
    - Precision
    - Recall
```

---

## ğŸ“š ç›¸å…³æ–‡ä»¶ç´¢å¼•

- **å…¥å£ç‚¹**: `examples/qa.py`
- **å·¥ä½œæµ**: `pikerag/workflows/qa.py`
- **æ£€ç´¢å™¨**: `pikerag/knowledge_retrievers/chroma_qa_retriever.py`
- **LLM å®¢æˆ·ç«¯**: `pikerag/llm_client/azure_open_ai_client.py`
- **æç¤ºæ¨¡æ¿**: `pikerag/prompts/qa/generation.py`
- **æ•°æ®åŠ è½½**: `pikerag/utils/data_protocol_utils.py`
- **è¯„ä¼°å™¨**: `pikerag/workflows/evaluation/evaluator.py`


