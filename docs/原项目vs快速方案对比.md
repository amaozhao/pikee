# PIKE-RAG: åŸé¡¹ç›® vs å¿«é€Ÿå®ç°æ–¹æ¡ˆå¯¹æ¯”

## ğŸ“Š æ¶æ„å¯¹æ¯”

### åŸé¡¹ç›®æ¶æ„ï¼ˆå®Œæ•´ç‰ˆï¼‰

```
pikerag/
â”œâ”€â”€ workflows/                    # å·¥ä½œæµå±‚
â”‚   â”œâ”€â”€ chunking.py              # æ–‡æ¡£åˆ‡åˆ†å·¥ä½œæµ
â”‚   â”œâ”€â”€ tagging.py               # æ ‡æ³¨å·¥ä½œæµ
â”‚   â”œâ”€â”€ qa.py                    # åŸºç¡€ QA å·¥ä½œæµ
â”‚   â”œâ”€â”€ qa_decompose.py          # é—®é¢˜åˆ†è§£å·¥ä½œæµ
â”‚   â”œâ”€â”€ qa_ircot.py              # è¿­ä»£æ¨ç†å·¥ä½œæµ
â”‚   â”œâ”€â”€ qa_self_ask.py           # è‡ªé—®è‡ªç­”å·¥ä½œæµ
â”‚   â””â”€â”€ qa_iter_retgen.py        # è¿­ä»£æ£€ç´¢ç”Ÿæˆ
â”‚
â”œâ”€â”€ knowledge_retrievers/         # æ£€ç´¢å™¨å±‚
â”‚   â”œâ”€â”€ chunk_atom_retriever.py  # åŒå±‚æ£€ç´¢å™¨ â˜…
â”‚   â”œâ”€â”€ chroma_qa_retriever.py   # Chroma æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ bm25_retriever.py        # BM25 æ£€ç´¢å™¨
â”‚   â””â”€â”€ mixins/
â”‚       â”œâ”€â”€ chroma_mixin.py      # Chroma æ“ä½œæ··å…¥
â”‚       â””â”€â”€ networkx_mixin.py    # å›¾éå†æ··å…¥
â”‚
â”œâ”€â”€ document_transformers/        # æ–‡æ¡£å¤„ç†å±‚
â”‚   â”œâ”€â”€ splitter/
â”‚   â”‚   â”œâ”€â”€ llm_powered_recursive_splitter.py
â”‚   â”‚   â””â”€â”€ recursive_sentence_splitter.py
â”‚   â””â”€â”€ tagger/
â”‚       â””â”€â”€ llm_powered_tagger.py
â”‚
â”œâ”€â”€ llm_client/                   # LLM å®¢æˆ·ç«¯å±‚
â”‚   â”œâ”€â”€ azure_open_ai_client.py
â”‚   â”œâ”€â”€ azure_meta_llama_client.py
â”‚   â””â”€â”€ hf_meta_llama_client.py
â”‚
â”œâ”€â”€ prompts/                      # Prompt ç®¡ç†å±‚
â”‚   â”œâ”€â”€ chunking/
â”‚   â”œâ”€â”€ decomposition/
â”‚   â”œâ”€â”€ qa/
â”‚   â”œâ”€â”€ tagging/
â”‚   â””â”€â”€ self_ask/
â”‚
â””â”€â”€ utils/                        # å·¥å…·å±‚
    â”œâ”€â”€ config_loader.py
    â”œâ”€â”€ data_protocol_utils.py
    â””â”€â”€ logger.py
```

### å¿«é€Ÿå®ç°æ–¹æ¡ˆï¼ˆç®€åŒ–ç‰ˆï¼‰

```
pike_rag_mvp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py               # âœ… ç»Ÿä¸€é…ç½®ï¼ˆPydanticï¼‰
â”‚   â”œâ”€â”€ document_loader.py      # âœ… ç»Ÿä¸€æ–‡æ¡£åŠ è½½
â”‚   â”œâ”€â”€ chunking.py             # âœ… ç®€åŒ–åˆ‡åˆ†ï¼ˆLangChainï¼‰
â”‚   â”œâ”€â”€ atom_extractor.py       # âœ… ç®€åŒ– Atom æå–
â”‚   â”œâ”€â”€ vector_store.py         # âœ… Qdrant å°è£…
â”‚   â”œâ”€â”€ retriever.py            # âœ… åŒå±‚æ£€ç´¢
â”‚   â””â”€â”€ qa_pipeline.py          # âœ… ç«¯åˆ°ç«¯é—®ç­”
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_build_knowledge.py   # âœ… ä¸€é”®æ„å»º
â”‚   â””â”€â”€ 02_run_qa.py            # âœ… ä¸€é”®é—®ç­”
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_pipeline.py         # âœ… å•å…ƒæµ‹è¯•
```

---

## ğŸ”„ æ ¸å¿ƒåŠŸèƒ½å¯¹æ¯”

### 1. æ–‡æ¡£åŠ è½½

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **å®ç°** | `document_loaders.common` | `UniversalDocumentLoader` | å¿«é€Ÿæ–¹æ¡ˆæ›´ç®€æ´ |
| **æ”¯æŒæ ¼å¼** | PDF, DOCX, TXT | PDF, DOCX, TXT, MD | ç›¸åŒ |
| **åŠ è½½æ–¹å¼** | éœ€æ‰‹åŠ¨æŒ‡å®š loader | è‡ªåŠ¨è¯†åˆ«æ ¼å¼ | å¿«é€Ÿæ–¹æ¡ˆæ›´æ™ºèƒ½ |
| **æ‰¹é‡åŠ è½½** | éœ€è‡ªå·±å®ç° | `load_directory()` | å¿«é€Ÿæ–¹æ¡ˆå†…ç½® |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®
from pikerag.document_loaders import get_loader
loader = get_loader(file_path="doc.pdf", file_type="pdf")
docs = loader.load()

# å¿«é€Ÿæ–¹æ¡ˆ
from src.document_loader import UniversalDocumentLoader
docs = UniversalDocumentLoader.load("doc.pdf")  # è‡ªåŠ¨è¯†åˆ«
```

### 2. æ–‡æ¡£åˆ‡åˆ†

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **å®ç°** | `LLMPoweredRecursiveSplitter` | `SmartChunker` | åŸºäº LangChain |
| **LLM è¾…åŠ©** | âœ… æœ‰ï¼ˆå¯é€‰ï¼‰ | âŒ æ—  | å¿«é€Ÿæ–¹æ¡ˆå»æ‰ä»¥é™ä½æˆæœ¬ |
| **é…ç½®æ–¹å¼** | YAML | Pydantic + å‚æ•° | å¿«é€Ÿæ–¹æ¡ˆæ›´çµæ´» |
| **æ€§èƒ½** | æ…¢ï¼ˆéœ€è°ƒç”¨ LLMï¼‰ | å¿«ï¼ˆçº¯è§„åˆ™ï¼‰ | å¿«é€Ÿæ–¹æ¡ˆæ›´å¿« |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®ï¼ˆéœ€ YAML é…ç½®ï¼‰
from pikerag.workflows.chunking import ChunkingWorkflow
workflow = ChunkingWorkflow(yaml_config)
workflow.run()

# å¿«é€Ÿæ–¹æ¡ˆï¼ˆç›´æ¥ä½¿ç”¨ï¼‰
from src.chunking import SmartChunker
chunker = SmartChunker(chunk_size=1000, chunk_overlap=200)
chunks = chunker.split_documents(docs)
```

### 3. åŸå­é—®é¢˜æå–

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **å®ç°** | `LLMPoweredTagger` | `AtomExtractor` | æ ¸å¿ƒé€»è¾‘ç›¸åŒ |
| **Prompt ç®¡ç†** | ç‹¬ç«‹ Protocol ç±» | å†…åµŒ Prompt | å¿«é€Ÿæ–¹æ¡ˆæ›´ç®€æ´ |
| **å¹¶è¡Œå¤„ç†** | âœ… æ”¯æŒ | âœ… æ”¯æŒ | ç›¸åŒ |
| **ç¼“å­˜æœºåˆ¶** | âœ… æœ‰ï¼ˆSQLiteï¼‰ | âŒ æ—  | å¯é€‰æ·»åŠ  |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®ï¼ˆéœ€å¤šä¸ªç»„ä»¶ï¼‰
from pikerag.workflows.tagging import TaggingWorkflow
workflow = TaggingWorkflow(yaml_config)
workflow.run()

# å¿«é€Ÿæ–¹æ¡ˆï¼ˆä¸€è¡Œè°ƒç”¨ï¼‰
from src.atom_extractor import AtomExtractor
extractor = AtomExtractor()
chunks_with_atoms = extractor.extract_atoms_batch(chunks)
```

### 4. å‘é‡å­˜å‚¨

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **å‘é‡åº“** | Chroma | **Qdrant** | å¿«é€Ÿæ–¹æ¡ˆæ€§èƒ½æ›´å¥½ |
| **éƒ¨ç½²** | æœ¬åœ°/å†…å­˜ | æœ¬åœ°/Docker/Cloud | Qdrant æ›´çµæ´» |
| **åŒå­˜å‚¨** | âœ… Chunk + Atom | âœ… Chunk + Atom | æ ¸å¿ƒé€»è¾‘ç›¸åŒ |
| **æ¥å£** | LangChain Chroma | Qdrant Client | ç›´æ¥ä½¿ç”¨ SDK |
| **è¿‡æ»¤èƒ½åŠ›** | åŸºç¡€ | å¼ºå¤§ | Qdrant æ”¯æŒå¤æ‚è¿‡æ»¤ |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®ï¼ˆChromaï¼‰
from pikerag.knowledge_retrievers.mixins.chroma_mixin import load_vector_store
chunk_store = load_vector_store(
    collection_name="chunks",
    persist_directory="./chroma_db",
    embedding=embedding_func,
    documents=docs,
    ids=doc_ids
)

# å¿«é€Ÿæ–¹æ¡ˆï¼ˆQdrantï¼‰
from src.vector_store import QdrantVectorStore
store = QdrantVectorStore(use_fastembed=True)
store.create_collections(vector_size=768)
store.add_chunks(chunks)
store.add_atoms(chunks)
```

### 5. æ£€ç´¢ç­–ç•¥

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **æ–¹æ³• 1** | `retrieve_atom_info_through_atom()` | `retrieve_through_atoms()` | ç›¸åŒé€»è¾‘ |
| **æ–¹æ³• 2** | `retrieve_atom_info_through_chunk()` | `retrieve_through_chunks()` | ç›¸åŒé€»è¾‘ |
| **æ–¹æ³• 3** | `retrieve_contents_by_query()` | `retrieve_hybrid()` | ç›¸åŒé€»è¾‘ |
| **è¿”å›æ ¼å¼** | `AtomRetrievalInfo` | ç®€åŒ– Dict | å¿«é€Ÿæ–¹æ¡ˆæ›´ç›´æ¥ |
| **å›¾éå†** | âœ… NetworkxMixin | âŒ æ— ï¼ˆå¯é€‰ï¼‰ | åŸé¡¹ç›®æ›´é«˜çº§ |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®
from pikerag.knowledge_retrievers.chunk_atom_retriever import ChunkAtomRetriever
retriever = ChunkAtomRetriever(retriever_config, log_dir, logger)
results = retriever.retrieve_contents_by_query(query)

# å¿«é€Ÿæ–¹æ¡ˆ
from src.retriever import PIKERetriever
retriever = PIKERetriever(vector_store)
results = retriever.retrieve_hybrid(query)
```

### 6. é—®ç­”æµç¨‹

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **åŸºç¡€ QA** | `QaWorkflow` | `PIKEQAPipeline` | ç›¸åŒé€»è¾‘ |
| **é—®é¢˜åˆ†è§£** | `QaDecompositionWorkflow` | âŒ æ— ï¼ˆPhase 2ï¼‰ | åŸé¡¹ç›®æ›´å®Œæ•´ |
| **è¿­ä»£æ¨ç†** | `QaIRCoTWorkflow` | âŒ æ— ï¼ˆPhase 2ï¼‰ | åŸé¡¹ç›®æ›´å®Œæ•´ |
| **è‡ªé—®è‡ªç­”** | `QaSelfAskWorkflow` | âŒ æ— ï¼ˆPhase 2ï¼‰ | åŸé¡¹ç›®æ›´å®Œæ•´ |
| **é…ç½®æ–¹å¼** | YAML | Pydantic | å¿«é€Ÿæ–¹æ¡ˆæ›´çµæ´» |

**ä»£ç å¯¹æ¯”**ï¼š

```python
# åŸé¡¹ç›®ï¼ˆéœ€ YAMLï¼‰
from pikerag.workflows.qa import QaWorkflow
workflow = QaWorkflow(yaml_config)
result = workflow.answer(qa_data, question_idx=0)

# å¿«é€Ÿæ–¹æ¡ˆï¼ˆç›´æ¥è°ƒç”¨ï¼‰
from src.qa_pipeline import PIKEQAPipeline
pipeline = PIKEQAPipeline(retriever)
result = pipeline.answer(question)
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### æ„å»ºçŸ¥è¯†åº“æ€§èƒ½

| æŒ‡æ ‡ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | å·®å¼‚ |
|------|--------|----------|------|
| **100 chunks åˆ‡åˆ†** | ~2 min | ~30 sec | **4x æ›´å¿«** |
| **100 chunks æå– Atoms** | ~10 min | ~10 min | ç›¸åŒ |
| **å‘é‡åŒ– + å­˜å‚¨** | ~1 min | ~30 sec | **2x æ›´å¿«** |
| **æ€»è®¡ï¼ˆ100 chunksï¼‰** | ~13 min | ~11 min | **ç•¥å¿«** |

### æŸ¥è¯¢æ€§èƒ½

| æŒ‡æ ‡ | åŸé¡¹ç›® (Chroma) | å¿«é€Ÿæ–¹æ¡ˆ (Qdrant) | å·®å¼‚ |
|------|-----------------|-------------------|------|
| **å‘é‡æ£€ç´¢å»¶è¿Ÿ** | ~200ms | ~100ms | **2x æ›´å¿«** |
| **æ‰¹é‡æ£€ç´¢ (Top 10)** | ~300ms | ~150ms | **2x æ›´å¿«** |
| **è¿‡æ»¤ + æ£€ç´¢** | ~500ms | ~200ms | **2.5x æ›´å¿«** |
| **QA æ€»å»¶è¿Ÿ** | ~4s | ~3s | **ç•¥å¿«** |

### å†…å­˜å ç”¨

| æŒ‡æ ‡ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | å·®å¼‚ |
|------|--------|----------|------|
| **10K chunks** | ~1.5GB | ~800MB | **æ›´èŠ‚çœ** |
| **50K chunks** | ~7GB | ~4GB | **æ›´èŠ‚çœ** |

---

## ğŸ’° æˆæœ¬å¯¹æ¯”ï¼ˆOpenAI APIï¼‰

### çŸ¥è¯†åº“æ„å»ºæˆæœ¬ï¼ˆå‡è®¾ 1000 chunksï¼‰

| é¡¹ç›® | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | å·®å¼‚ |
|------|--------|----------|------|
| **æ–‡æ¡£åˆ‡åˆ†** | $2 (LLM) | $0 (è§„åˆ™) | **çœ $2** |
| **Atom æå–** | $10 (GPT-4) | $10 (GPT-4) | ç›¸åŒ |
| **Embedding** | $0.13 (ada-002) | $0 (FastEmbed) | **çœ $0.13** |
| **æ€»è®¡** | **$12.13** | **$10** | **çœ 17%** |

### æŸ¥è¯¢æˆæœ¬ï¼ˆ1000 æ¬¡æŸ¥è¯¢ï¼‰

| é¡¹ç›® | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | å·®å¼‚ |
|------|--------|----------|------|
| **LLM ç”Ÿæˆ** | $20 (GPT-4) | $20 (GPT-4) | ç›¸åŒ |
| **å‘é‡æ£€ç´¢** | $0 (æœ¬åœ°) | $0 (æœ¬åœ°) | ç›¸åŒ |
| **æ€»è®¡** | **$20** | **$20** | ç›¸åŒ |

---

## ğŸ¯ åŠŸèƒ½å®Œæ•´åº¦å¯¹æ¯”

### Phase 1: æ ¸å¿ƒåŠŸèƒ½ï¼ˆMVPï¼‰

| åŠŸèƒ½ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| æ–‡æ¡£åŠ è½½ | âœ… | âœ… | ç›¸åŒ |
| æ™ºèƒ½åˆ‡åˆ† | âœ… | âœ… | å¿«é€Ÿæ–¹æ¡ˆå»æ‰ LLM è¾…åŠ© |
| Atom æå– | âœ… | âœ… | ç›¸åŒ |
| åŒå‘é‡å­˜å‚¨ | âœ… | âœ… | å‘é‡åº“ä¸åŒ |
| æ··åˆæ£€ç´¢ | âœ… | âœ… | ç›¸åŒ |
| åŸºç¡€ QA | âœ… | âœ… | ç›¸åŒ |

**ç»“è®º**: æ ¸å¿ƒåŠŸèƒ½å®Œå…¨å¯¹é½ âœ…

### Phase 2: é«˜çº§åŠŸèƒ½

| åŠŸèƒ½ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| é—®é¢˜åˆ†è§£ | âœ… | âŒ | åŸé¡¹ç›®æœ‰å®Œæ•´å®ç° |
| è¿­ä»£æ¨ç† | âœ… | âŒ | åŸé¡¹ç›®æœ‰å®Œæ•´å®ç° |
| è‡ªé—®è‡ªç­” | âœ… | âŒ | åŸé¡¹ç›®æœ‰å®Œæ•´å®ç° |
| è¿­ä»£æ£€ç´¢ç”Ÿæˆ | âœ… | âŒ | åŸé¡¹ç›®æœ‰å®Œæ•´å®ç° |
| å›¾éå† | âœ… | âŒ | åŸé¡¹ç›®æœ‰ NetworkxMixin |
| è¯„ä¼°æŒ‡æ ‡ | âœ… | âŒ | åŸé¡¹ç›®æœ‰å®Œæ•´è¯„ä¼°ç³»ç»Ÿ |

**ç»“è®º**: é«˜çº§åŠŸèƒ½åŸé¡¹ç›®æ›´å®Œæ•´ï¼Œå¿«é€Ÿæ–¹æ¡ˆå¯åç»­æ·»åŠ  ğŸ”„

---

## ğŸ› ï¸ å¼€å‘ä½“éªŒå¯¹æ¯”

### é…ç½®ç®¡ç†

**åŸé¡¹ç›®ï¼ˆYAMLï¼‰**ï¼š

```yaml
# examples/hotpotqa/configs/atomic_decompose.yml
experiment_name: atomic_decompose
log_root_dir: logs/hotpotqa

workflow:
  module_path: pikerag.workflows.qa_decompose
  class_name: QaDecompositionWorkflow
  args:
    max_num_question: 5

retriever:
  module_path: pikerag.knowledge_retrievers
  class_name: ChunkAtomRetriever
  args:
    retrieve_k: 8
    vector_store:
      collection_name: dev_500_ada
      # ... æ›´å¤šé…ç½®
```

**å¿«é€Ÿæ–¹æ¡ˆï¼ˆPydanticï¼‰**ï¼š

```python
# src/config.py
from pydantic import BaseModel

class PIKERAGConfig(BaseModel):
    llm: LLMConfig = Field(default_factory=LLMConfig)
    retrieval: RetrievalConfig = Field(default_factory=RetrievalConfig)
    # ...

# ä½¿ç”¨
from src.config import config
config.retrieval.chunk_retrieve_k = 8
```

**å¯¹æ¯”**ï¼š
- âœ… å¿«é€Ÿæ–¹æ¡ˆï¼šç±»å‹å®‰å…¨ã€IDE æç¤ºã€çµæ´»
- âœ… åŸé¡¹ç›®ï¼šå£°æ˜å¼ã€æ˜“äºç‰ˆæœ¬æ§åˆ¶

### ä»£ç å¤æ‚åº¦

| æŒ‡æ ‡ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | è¯´æ˜ |
|------|--------|----------|------|
| **æ ¸å¿ƒä»£ç è¡Œæ•°** | ~5000 | ~1500 | **å¿«é€Ÿæ–¹æ¡ˆç®€æ´ 3x** |
| **æ–‡ä»¶æ•°é‡** | ~50 | ~10 | **å¿«é€Ÿæ–¹æ¡ˆç®€æ´ 5x** |
| **ä¾èµ–æ•°é‡** | 20+ | 10 | **å¿«é€Ÿæ–¹æ¡ˆæ›´è½»é‡** |
| **å­¦ä¹ æ›²çº¿** | é™¡å³­ | å¹³ç¼“ | **å¿«é€Ÿæ–¹æ¡ˆæ›´æ˜“ä¸Šæ‰‹** |

### è°ƒè¯•ä½“éªŒ

**åŸé¡¹ç›®**ï¼š
- âŒ å¤šå±‚æŠ½è±¡ï¼ˆWorkflow â†’ Retriever â†’ Mixinï¼‰
- âŒ YAML é…ç½®éš¾ä»¥è°ƒè¯•
- âœ… æ—¥å¿—è¯¦ç»†

**å¿«é€Ÿæ–¹æ¡ˆ**ï¼š
- âœ… æ‰å¹³åŒ–è®¾è®¡ï¼Œè°ƒè¯•ç®€å•
- âœ… Loguru æ—¥å¿—ç›´è§‚
- âœ… ç±»å‹æç¤ºå®Œæ•´

---

## ğŸš€ éƒ¨ç½²å¯¹æ¯”

### åŸé¡¹ç›®éƒ¨ç½²

```bash
# 1. é…ç½®ç¯å¢ƒå˜é‡
vim .env

# 2. å‡†å¤‡ YAML é…ç½®
vim examples/hotpotqa/configs/qa_chunk.yml

# 3. æ„å»ºçŸ¥è¯†åº“
python examples/chunking.py examples/biology/configs/chunking.yml
python examples/tagging.py examples/hotpotqa/configs/tagging.yml

# 4. è¿è¡Œ QA
python examples/qa.py examples/hotpotqa/configs/qa_chunk.yml
```

**å¤æ‚åº¦**: â­â­â­â­ (4/5)

### å¿«é€Ÿæ–¹æ¡ˆéƒ¨ç½²

```bash
# 1. ä¸€é”®å¯åŠ¨ Qdrant
docker-compose up -d qdrant

# 2. æ„å»ºçŸ¥è¯†åº“
python scripts/01_build_knowledge.py --input data/documents

# 3. è¿è¡Œ QA
python scripts/02_run_qa.py --question "ä½ çš„é—®é¢˜"
```

**å¤æ‚åº¦**: â­â­ (2/5)

---

## ğŸ“Š é€‰æ‹©å»ºè®®

### é€‰æ‹©åŸé¡¹ç›®ï¼Œå¦‚æœä½ éœ€è¦ï¼š

1. âœ… **å­¦æœ¯ç ”ç©¶**: å¤ç°è®ºæ–‡å®éªŒ
2. âœ… **å¤æ‚æ¨ç†**: é—®é¢˜åˆ†è§£ã€å¤šè·³æ¨ç†
3. âœ… **å®Œæ•´è¯„ä¼°**: éœ€è¦ EM, F1 ç­‰æŒ‡æ ‡
4. âœ… **æ·±åº¦å®šåˆ¶**: éœ€è¦ä¿®æ”¹åº•å±‚é€»è¾‘
5. âœ… **ç ”ç©¶å­¦ä¹ **: å­¦ä¹  PIKE-RAG å®Œæ•´è®¾è®¡

### é€‰æ‹©å¿«é€Ÿæ–¹æ¡ˆï¼Œå¦‚æœä½ éœ€è¦ï¼š

1. âœ… **å¿«é€ŸéªŒè¯**: 2-3 å¤©å†…éªŒè¯å¯è¡Œæ€§
2. âœ… **ç”Ÿäº§éƒ¨ç½²**: ç®€å•ã€ç¨³å®šã€æ˜“ç»´æŠ¤
3. âœ… **æˆæœ¬ä¼˜å…ˆ**: å‡å°‘ LLM API è°ƒç”¨
4. âœ… **å›¢é˜Ÿåä½œ**: ä»£ç ç®€æ´æ˜“æ‡‚
5. âœ… **çµæ´»æ‰©å±•**: æ˜“äºé›†æˆç°æœ‰ç³»ç»Ÿ

---

## ğŸ”„ è¿ç§»è·¯å¾„

### ä»åŸé¡¹ç›®è¿ç§»åˆ°å¿«é€Ÿæ–¹æ¡ˆ

```python
# Step 1: å¯¼å‡ºæ•°æ®
# åŸé¡¹ç›®å·²æ„å»ºçš„çŸ¥è¯†åº“æ•°æ®åœ¨ Chroma ä¸­
# éœ€è¦å¯¼å‡º chunks_with_atoms.jsonl

# Step 2: å¯¼å…¥åˆ° Qdrant
from src.vector_store import QdrantVectorStore
import jsonlines

store = QdrantVectorStore()
store.create_collections(768)

chunks_with_atoms = []
with jsonlines.open('chunks_with_atoms.jsonl') as f:
    for obj in f:
        doc = Document(
            page_content=obj['content'],
            metadata={'chunk_id': obj['chunk_id'], 'atoms': obj['atoms']}
        )
        chunks_with_atoms.append(doc)

store.add_chunks(chunks_with_atoms)
store.add_atoms(chunks_with_atoms)

# Step 3: æµ‹è¯•
from src.retriever import PIKERetriever
from src.qa_pipeline import PIKEQAPipeline

retriever = PIKERetriever(store)
qa = PIKEQAPipeline(retriever)
result = qa.answer("æµ‹è¯•é—®é¢˜")
```

### ä»å¿«é€Ÿæ–¹æ¡ˆè¿ç§»åˆ°åŸé¡¹ç›®

```python
# å¯¼å‡º Qdrant æ•°æ®ä¸º JSONL
from src.vector_store import QdrantVectorStore
import jsonlines

store = QdrantVectorStore()

# è·å–æ‰€æœ‰ chunks
chunks = store.client.scroll(
    collection_name=store.chunk_collection,
    limit=10000
)[0]

# ä¿å­˜ä¸ºåŸé¡¹ç›®æ ¼å¼
with jsonlines.open('for_pike_rag.jsonl', 'w') as f:
    for chunk in chunks:
        f.write({
            'chunk_id': chunk.payload['chunk_id'],
            'content': chunk.payload['content'],
            'title': chunk.payload.get('title', ''),
            'atom_questions': chunk.payload['atoms']
        })
```

---

## ğŸ’¡ æœ€ç»ˆæ¨è

### åœºæ™¯ 1: å¿«é€ŸéªŒè¯ï¼ˆ1-2 å‘¨ï¼‰

**æ¨è**: å¿«é€Ÿæ–¹æ¡ˆ â­â­â­â­â­

- 2-3 å¤©å®ç° MVP
- å¿«é€ŸéªŒè¯å¯è¡Œæ€§
- æˆæœ¬ä½ã€é£é™©å°

### åœºæ™¯ 2: å­¦æœ¯ç ”ç©¶

**æ¨è**: åŸé¡¹ç›® â­â­â­â­â­

- å®Œæ•´å¤ç°è®ºæ–‡
- å¤šç§æ¨ç†ç­–ç•¥
- æ ‡å‡†è¯„ä¼°æŒ‡æ ‡

### åœºæ™¯ 3: ç”Ÿäº§éƒ¨ç½²

**æ¨è**: å¿«é€Ÿæ–¹æ¡ˆ â†’ é€æ­¥å¢å¼º â­â­â­â­

- å…ˆç”¨å¿«é€Ÿæ–¹æ¡ˆä¸Šçº¿
- æ ¹æ®éœ€æ±‚é€æ­¥æ·»åŠ é«˜çº§åŠŸèƒ½
- çµæ´»å¯æ§

### åœºæ™¯ 4: æ··åˆæ–¹æ¡ˆï¼ˆæ¨èï¼‰

**æ¨è**: å¿«é€Ÿæ–¹æ¡ˆ + åŸé¡¹ç›®æ¨¡å— â­â­â­â­â­

```python
# ä½¿ç”¨å¿«é€Ÿæ–¹æ¡ˆçš„ç®€æ´æ¶æ„
from src.vector_store import QdrantVectorStore
from src.retriever import PIKERetriever

# å¼•å…¥åŸé¡¹ç›®çš„é«˜çº§åŠŸèƒ½
from pikerag.workflows.qa_decompose import QaDecompositionWorkflow

# æœ€ä½³å®è·µï¼šç®€æ´ + å¼ºå¤§
```

---

**æ€»ç»“**ï¼š

| ç»´åº¦ | åŸé¡¹ç›® | å¿«é€Ÿæ–¹æ¡ˆ | æœ€ä½³é€‰æ‹© |
|------|--------|----------|----------|
| **å¼€å‘é€Ÿåº¦** | æ…¢ | **å¿«** | å¿«é€Ÿæ–¹æ¡ˆ âœ… |
| **åŠŸèƒ½å®Œæ•´åº¦** | **å®Œæ•´** | åŸºç¡€ | åŸé¡¹ç›® âœ… |
| **æ€§èƒ½** | å¥½ | **æ›´å¥½** | å¿«é€Ÿæ–¹æ¡ˆ âœ… |
| **å¯ç»´æŠ¤æ€§** | ä¸­ç­‰ | **ä¼˜ç§€** | å¿«é€Ÿæ–¹æ¡ˆ âœ… |
| **å­¦ä¹ ä»·å€¼** | **é«˜** | ä¸­ç­‰ | åŸé¡¹ç›® âœ… |
| **ç”Ÿäº§å°±ç»ª** | éœ€è°ƒæ•´ | **å°±ç»ª** | å¿«é€Ÿæ–¹æ¡ˆ âœ… |

**ç»¼åˆæ¨è**: å¿«é€Ÿæ–¹æ¡ˆ (MVP) â†’ é€æ­¥é›†æˆåŸé¡¹ç›®é«˜çº§åŠŸèƒ½ ğŸ¯

